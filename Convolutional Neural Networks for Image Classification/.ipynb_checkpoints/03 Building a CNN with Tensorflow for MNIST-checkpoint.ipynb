{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Obtaining Data\n",
    "- Download MNIST dataset\n",
    "- Examine images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather the MNIST dataset \n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# Verify the length of the datasets\n",
    "print(len(x_train))\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify an individual image array 28 x 28\n",
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x63ebc3d10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize an individual image\n",
    "plt.imshow(x_train[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Verify test data is different from the training data\n",
    "plt.imshow(x_test[0], cmap='gray')\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Layers\n",
    "- Convolution Layer\n",
    "- Flatten Layer\n",
    "- Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTModel(Model):\n",
    "    def __init__(self):\n",
    "        super(MNISTModel, self).__init__()\n",
    "        self.conv1 = Conv2D(32, 3, activation='relu')\n",
    "        self.flatten = Flatten()\n",
    "        self.dense1 = Dense(128, activation='relu') # for each output from convolution layer, there are 4 outputs\n",
    "        self.dense2 = Dense(10, activation='softmax') # 10 outputs for each of the possible digits, softmax is used to calculate the probabilty of each output\n",
    "        \n",
    "    def call(self, x):\n",
    "        x1 = self.conv1(x) # Storing the 32 outputs into the x1\n",
    "        x2 = self.flatten(x1) # Flatten the 32 outputs into x2\n",
    "        x3 = self.dense1(x2) # Calculate the possible outputs from the flattened array\n",
    "        return self.dense2(x3) # Calculate the maximum probability of the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the MNISTModel\n",
    "model = MNISTModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#kernel_size = 3\n",
    "#activation = 'relu'\n",
    "#filters = 32\n",
    "\n",
    "# Apply filters to abstract the image and reduce the size\n",
    "#Conv2D(filters, kernel_size=kernel_size, activation=activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose is to take a 2D array and flatten it into a 1D array\n",
    "#Flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No. of neurons should correspond to the number of outputs\n",
    "# Activation should be 'relu' unless its the last one which will be 'softmax' (softmax is used to calculate the density)\n",
    "#Dense(neurons, activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Loss and Optimizer\n",
    "- Add a loss function\n",
    "- Add an optimizer function\n",
    "- Add a way to measure loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the overall loss depending on which category the current output creates\n",
    "# Minimizes the possibility that the output belongs to more than 1 category (we only want it to belong to 1)\n",
    "loss_function = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "# Adam optimizer modifies the learning rate accordingly depending on how well the accuracy is increasing\n",
    "# If accuracy is increasing a lot, increase learning rate arrive at the correct answer faster\n",
    "# If the accuracy is not increasing a lot, decrease the learning rate to get more granularity\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The different labels allow you to monitor changes in tf.board or other monitoring options\n",
    "# Takes the average of the overall losses in the training run\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "\n",
    "# Matches the loss type because the output should only correspond to one category at a time\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes the average of the overall losses in the test run\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "\n",
    "# Matches the loss type because the output should only correspond to one category at a time\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Train and Test Step\n",
    "- Add the function to run when training the model (will modify the weights)\n",
    "- Add the function to run when testing the model (will not modify weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inputs, outputs):\n",
    "    # GradientTape is used to apply the gradient and change the weights and biases\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Getting the model outputs based on the current weights and biases\n",
    "        predictions = model(inputs)\n",
    "        # Calculate the loss based on what the model is outputting and the expected output\n",
    "        # Want to minimize this loss but need to know what it is in the first place\n",
    "        loss = loss_function(outputs, predictions)\n",
    "    # trainable_variables fields are from the Model class\n",
    "    # Calculate new trainable variables to try to minimize the loss\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    # Use the optimizer to apply the new weights and biases to modify the graph and get a lower loss\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    # Calculate the current loss and accuracy\n",
    "    train_loss(loss)\n",
    "    train_accuracy(outputs, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(inputs, outputs):\n",
    "    # Getting the model outputs based on the current weights and biases\n",
    "    predictions = model(inputs)\n",
    "    # Calculate the loss based on what the model is outputting and the expected output\n",
    "    loss = loss_function(outputs, predictions)\n",
    "\n",
    "    \n",
    "    # Calculate the current loss and accuracy\n",
    "    test_loss(loss)\n",
    "    test_accuracy(outputs, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Formatting Data\n",
    "- Usually happens when you gather the data\n",
    "- Format inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data to be between 0 and 1 (In this dataset, its 255 since the values go between 0 and 255)\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the way the data is formatted so that it has another dimension so the result of each array is in another dimension\n",
    "# Change each element in an array to be its own array\n",
    "# Input needs to be in 4 dimensions \n",
    "x_train = x_train[..., tf.newaxis]\n",
    "x_test = x_test[..., tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.01176471]],\n",
       "\n",
       "        [[0.07058824]],\n",
       "\n",
       "        [[0.07058824]],\n",
       "\n",
       "        [[0.07058824]],\n",
       "\n",
       "        [[0.49411765]],\n",
       "\n",
       "        [[0.53333333]],\n",
       "\n",
       "        [[0.68627451]],\n",
       "\n",
       "        [[0.10196078]],\n",
       "\n",
       "        [[0.65098039]],\n",
       "\n",
       "        [[1.        ]],\n",
       "\n",
       "        [[0.96862745]],\n",
       "\n",
       "        [[0.49803922]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.11764706]],\n",
       "\n",
       "        [[0.14117647]],\n",
       "\n",
       "        [[0.36862745]],\n",
       "\n",
       "        [[0.60392157]],\n",
       "\n",
       "        [[0.66666667]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.88235294]],\n",
       "\n",
       "        [[0.6745098 ]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.94901961]],\n",
       "\n",
       "        [[0.76470588]],\n",
       "\n",
       "        [[0.25098039]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.19215686]],\n",
       "\n",
       "        [[0.93333333]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.98431373]],\n",
       "\n",
       "        [[0.36470588]],\n",
       "\n",
       "        [[0.32156863]],\n",
       "\n",
       "        [[0.32156863]],\n",
       "\n",
       "        [[0.21960784]],\n",
       "\n",
       "        [[0.15294118]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.07058824]],\n",
       "\n",
       "        [[0.85882353]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.77647059]],\n",
       "\n",
       "        [[0.71372549]],\n",
       "\n",
       "        [[0.96862745]],\n",
       "\n",
       "        [[0.94509804]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.31372549]],\n",
       "\n",
       "        [[0.61176471]],\n",
       "\n",
       "        [[0.41960784]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.80392157]],\n",
       "\n",
       "        [[0.04313725]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.16862745]],\n",
       "\n",
       "        [[0.60392157]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.05490196]],\n",
       "\n",
       "        [[0.00392157]],\n",
       "\n",
       "        [[0.60392157]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.35294118]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.54509804]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.74509804]],\n",
       "\n",
       "        [[0.00784314]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.04313725]],\n",
       "\n",
       "        [[0.74509804]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.2745098 ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.1372549 ]],\n",
       "\n",
       "        [[0.94509804]],\n",
       "\n",
       "        [[0.88235294]],\n",
       "\n",
       "        [[0.62745098]],\n",
       "\n",
       "        [[0.42352941]],\n",
       "\n",
       "        [[0.00392157]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.31764706]],\n",
       "\n",
       "        [[0.94117647]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.46666667]],\n",
       "\n",
       "        [[0.09803922]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.17647059]],\n",
       "\n",
       "        [[0.72941176]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.58823529]],\n",
       "\n",
       "        [[0.10588235]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.0627451 ]],\n",
       "\n",
       "        [[0.36470588]],\n",
       "\n",
       "        [[0.98823529]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.73333333]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.97647059]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.97647059]],\n",
       "\n",
       "        [[0.25098039]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.18039216]],\n",
       "\n",
       "        [[0.50980392]],\n",
       "\n",
       "        [[0.71764706]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.81176471]],\n",
       "\n",
       "        [[0.00784314]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.15294118]],\n",
       "\n",
       "        [[0.58039216]],\n",
       "\n",
       "        [[0.89803922]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.98039216]],\n",
       "\n",
       "        [[0.71372549]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.09411765]],\n",
       "\n",
       "        [[0.44705882]],\n",
       "\n",
       "        [[0.86666667]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.78823529]],\n",
       "\n",
       "        [[0.30588235]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.09019608]],\n",
       "\n",
       "        [[0.25882353]],\n",
       "\n",
       "        [[0.83529412]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.77647059]],\n",
       "\n",
       "        [[0.31764706]],\n",
       "\n",
       "        [[0.00784314]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.07058824]],\n",
       "\n",
       "        [[0.67058824]],\n",
       "\n",
       "        [[0.85882353]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.76470588]],\n",
       "\n",
       "        [[0.31372549]],\n",
       "\n",
       "        [[0.03529412]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.21568627]],\n",
       "\n",
       "        [[0.6745098 ]],\n",
       "\n",
       "        [[0.88627451]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.95686275]],\n",
       "\n",
       "        [[0.52156863]],\n",
       "\n",
       "        [[0.04313725]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.53333333]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.99215686]],\n",
       "\n",
       "        [[0.83137255]],\n",
       "\n",
       "        [[0.52941176]],\n",
       "\n",
       "        [[0.51764706]],\n",
       "\n",
       "        [[0.0627451 ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]],\n",
       "\n",
       "        [[0.        ]]]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing up the data, shuffling by 10,000 and then returning batches of 32\n",
    "# Tries to prevent overfitting and false positives\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(32)\n",
    "\n",
    "# Attempt to feed in batches of 32 since the dataset is large\n",
    "test_data = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Training\n",
    "- Write the train loop\n",
    "- Train and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer mnist_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Epochs: 1, Train Loss: 0.1342819482088089, Train Accuracy: 0.959933340549469, Test Loss: 0.06557536125183105, Test Accuracy: 0.978600025177002\n",
      "Epochs: 2, Train Loss: 0.04153291881084442, Train Accuracy: 0.9872666597366333, Test Loss: 0.05793168768286705, Test Accuracy: 0.9807999730110168\n",
      "Epochs: 3, Train Loss: 0.02179376594722271, Train Accuracy: 0.993066668510437, Test Loss: 0.05405556410551071, Test Accuracy: 0.9829000234603882\n",
      "Epochs: 4, Train Loss: 0.013260572217404842, Train Accuracy: 0.9958166480064392, Test Loss: 0.06107764691114426, Test Accuracy: 0.9830999970436096\n",
      "Epochs: 5, Train Loss: 0.008021503686904907, Train Accuracy: 0.9972166419029236, Test Loss: 0.06627218425273895, Test Accuracy: 0.9822999835014343\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for train_inputs, train_labels in train_data:\n",
    "        train_step(train_inputs, train_labels)\n",
    "        \n",
    "    for test_inputs, test_labels in test_data:\n",
    "        test_step(test_inputs, test_labels)\n",
    "        \n",
    "    template = 'Epochs: {}, Train Loss: {}, Train Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
    "    print(template.format(epoch+1, train_loss.result(), train_accuracy.result(), test_loss.result(), test_accuracy.result()))\n",
    "          \n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training and testing accuracy after one epoch was already around 97%. Therefore, we did not need to run it too many times to see a slight improvement. Anything over 90% is already a pretty well trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
